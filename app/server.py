import sys
import os
import uuid
import shutil
import pandas as pd
import uvicorn
import io
from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.responses import FileResponse
from pydantic import BaseModel
from typing import List, Optional, Dict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.services.ingestion import load_file
from app.services.workflow import create_workflow
from app.utils.tools import AuditLogger

app = FastAPI(title="Agentic Data Analyst API")

# ==========================================
# ğŸ“‚ è·¯å¾„é…ç½®
# ==========================================
UPLOAD_DIR = "temp_uploads"
OUTPUT_DIR = "temp_outputs"
os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ==========================================
# ğŸ§  Session ç®¡ç†
# ==========================================
class SessionData:
    def __init__(self):
        self.dfs_context = {}  # å­˜æ”¾ DataFrames
        self.workflow_app = None # ç¼–è¯‘å¥½çš„ Graph

sessions: dict[str, SessionData] = {}

# ==========================================
# ğŸ“¦ æ•°æ®æ¨¡å‹
# ==========================================
class ChatRequest(BaseModel):
    session_id: str
    message: str

class ChatResponse(BaseModel):
    response_text: str
    chart_jsons: List[str] = []
    download_url: Optional[str] = None
    audit_summary: Optional[str] = None

# ==========================================
# ğŸ› ï¸ æ ¸å¿ƒå·¥å…·ï¼šçº¯å‡€ç‰ˆå¯¼å‡º (User Request Fix)
# ==========================================
def save_full_context_excel(result_df: Optional[pd.DataFrame], 
                          dfs_context: Dict[str, pd.DataFrame], 
                          audit: AuditLogger, 
                          output_path: str):
    """
    å°† ã€æ‰€æœ‰å½“å‰æ•°æ®è¡¨ã€‘ + ã€å®¡è®¡æ—¥å¿—ã€‘ ä¿å­˜åˆ°ä¸€ä¸ª Excelã€‚
    ä¿®æ”¹ç‚¹ï¼šä¸å†å¼ºåˆ¶ç”Ÿæˆâ€œåˆ†æç»“æœâ€Sheetï¼Œè€Œæ˜¯ç›´æ¥ä¿å­˜ dfs_context ä¸­çš„æ–‡ä»¶ï¼Œ
    ç¡®ä¿æ–‡ä»¶åå’Œ Sheet åä¸€ä¸€å¯¹åº”ï¼Œä¸”å†…å®¹ä¸ºæ¸…æ´—åçš„ç‰ˆæœ¬ã€‚
    """
    with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
        saved_sheets = set()

        # 1. ä¼˜å…ˆå†™å…¥ä¸Šä¸‹æ–‡ä¸­çš„æ‰€æœ‰æ•°æ®è¡¨ (Cleaned Files)
        # å› ä¸º Worker å·²ç»æ‰§è¡Œäº† dfs[name] = dfï¼Œæ‰€ä»¥è¿™é‡Œå°±æ˜¯æ¸…æ´—åçš„æ•°æ®
        if dfs_context:
            for name, df in dfs_context.items():
                if name.startswith("__"): continue # è·³è¿‡ç³»ç»Ÿå˜é‡
                
                # Sheet åå¤„ç† (Excel é™åˆ¶ 31 å­—ç¬¦)
                # å»æ‰ .xlsx åç¼€ï¼Œç›´æ¥ç”¨æ–‡ä»¶åï¼Œç®€æ´æ˜äº†
                safe_name = os.path.splitext(name)[0][:30]
                
                # é¿å…é‡å
                counter = 1
                original_name = safe_name
                while safe_name in saved_sheets:
                    safe_name = f"{original_name}_{counter}"
                    counter += 1
                
                df.to_excel(writer, sheet_name=safe_name, index=False)
                saved_sheets.add(safe_name)
        
        # 2. (å¯é€‰) åªæœ‰å½“ result_df æ˜¯å…¨æ–°çš„èšåˆç»“æœ(ä¸åœ¨dfs_contexté‡Œ)æ—¶ï¼Œæ‰ä¿å­˜
        # ä½†ä¸ºäº†æ»¡è¶³â€œä¸éœ€è¦åˆ†æç»“æœSheetâ€çš„è¦æ±‚ï¼Œè¿™é‡Œç›´æ¥æ³¨é‡Šæ‰ï¼Œé™¤éä½ åšèšåˆåˆ†æ
        # if result_df is not None: ...
        
        # 3. å†™å…¥å®¡è®¡æ—¥å¿— (Audit)
        if audit:
            log_df = audit.get_log_df()
            if not log_df.empty:
                log_df.to_excel(writer, sheet_name='å¤„ç†æ—¥å¿—(Audit)', index=False)
            
            # 4. å†™å…¥è¢«å‰”é™¤çš„æ•°æ® (Exclusions)
            for name, ex_df in audit.excluded_data.items():
                # ç®€åŒ–çš„ Sheet å
                clean_name = os.path.splitext(name)[0][:10]
                sheet_name = f"å‰”é™¤_{clean_name}"[:30]
                ex_df.to_excel(writer, sheet_name=sheet_name, index=False)
                
# ==========================================
# ğŸš€ API æ¥å£
# ==========================================

@app.post("/upload")
async def upload_files(session_id: str = Form(...), files: List[UploadFile] = File(...)):
    if session_id not in sessions:
        sessions[session_id] = SessionData()
    
    session = sessions[session_id]
    loaded_info = []

    for file in files:
        file_path = os.path.join(UPLOAD_DIR, f"{session_id}_{file.filename}")
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        
        try:
            df = load_file(file_path)
            session.dfs_context[file.filename] = df
            # âœ… æ–°å¢ï¼šåˆ›å»ºéšå½¢å¤‡ä»½ (Deep Copy)
            session.dfs_context[f"__backup_{file.filename}"] = df.copy(deep=True)
            loaded_info.append(f"{file.filename} (Rows: {len(df)})")
        except Exception as e:
            return {"error": f"Failed to load {file.filename}: {str(e)}"}

    session.workflow_app = create_workflow(session.dfs_context)
    return {"message": "Upload success", "details": loaded_info}

@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    session_id = request.session_id
    if session_id not in sessions:
        raise HTTPException(status_code=404, detail="Session expired")
    
    session = sessions[session_id]
    if not session.workflow_app:
        session.workflow_app = create_workflow({})

    state = {
        "messages": [], 
        "user_instruction": request.message,
        "error_count": 0,
        "chart_jsons": [],
        "reply": ""
    }
    
    # æ¸…ç†æ—§çŠ¶æ€ (ä¿ç•™ context ä¸­çš„æ•°æ®è¡¨ï¼Œæ¸…é™¤ä¸Šä¸€æ¬¡çš„ä¸´æ—¶ç»“æœ)
    if '__last_result_df__' in session.dfs_context: del session.dfs_context['__last_result_df__']
    if '__last_audit__' in session.dfs_context: del session.dfs_context['__last_audit__']

    # åˆå§‹åŒ–è¿”å›å˜é‡
    chart_jsons = []
    download_link = None
    audit_summary = None
    steps_log = []
    final_answer = ""
    error_msg = None

    try:
        # è¿è¡Œ Workflow
        for event in session.workflow_app.stream(state, config={"recursion_limit": 30}):
            for key, val in event.items():
                if key == "executor":
                    if "messages" in val:
                        raw_msg = val["messages"][-1].content
                        
                        # 1. æå– PLAN (æ€è€ƒè¿‡ç¨‹)
                        if "# PLAN:" in raw_msg:
                            try:
                                plan_part = raw_msg.split("# PLAN:")[1].split("# CODE")[0].strip()
                                # ç§»é™¤ # å·ï¼Œé˜²æ­¢å­—ä½“è¿‡å¤§
                                plan_clean = "\n".join([line.strip("# ").strip() for line in plan_part.splitlines()])
                                steps_log.append(f"ğŸ§  **æ€è€ƒ**: {plan_clean}")
                            except:
                                pass
                        
                        # 2. æå– Insights (åˆ†æç»“è®º)
                        # è¯†åˆ«åŒ…å«ç»“è®ºçš„æ–‡æœ¬ï¼Œå¹¶æ¸…æ´—
                        if "ğŸ“Š åˆ†æç»“è®º" in raw_msg or "âœ…" in raw_msg or "æ¸…æ´—å®Œæˆ" in raw_msg:
                            clean = raw_msg.replace("(Signal: WORKER_DONE)", "").strip()
                            if clean not in final_answer:
                                final_answer += clean + "\n\n"

                        # 3. æ‹¦æˆªæŠ¥é”™
                        if "âŒ Runtime Error" in raw_msg:
                            steps_log.append("ğŸ”§ **è‡ªæ„ˆ**: æ£€æµ‹åˆ°ä»£ç é”™è¯¯ï¼Œæ­£åœ¨è‡ªåŠ¨ä¿®æ­£...")

                    if "chart_jsons" in val:
                        chart_jsons.extend(val["chart_jsons"])
                
                elif key == "general_chat":
                    if "messages" in val:
                        final_answer += val["messages"][0].content

        # ==========================================
        # ğŸ’¾ æ–‡ä»¶å¯¼å‡ºé€»è¾‘ (æ ¸å¿ƒä¿®æ”¹)
        # ==========================================
        # å³ä½¿æ²¡æœ‰ __last_result_df__ï¼Œåªè¦æœ‰æ•°æ®è¡¨å’Œå®¡è®¡æ—¥å¿—ï¼Œä¹Ÿå¯ä»¥å¯¼å‡º
        # ä½†é€šå¸¸ Workflow ç»“æŸæ—¶è‡³å°‘ä¼šç”Ÿæˆå®¡è®¡å¯¹è±¡
        
        result_df = session.dfs_context.pop('__last_result_df__', None)
        audit_logger = session.dfs_context.pop('__last_audit__', None)
        
        # åªè¦æœ‰æ•°æ®æˆ–è€…æœ‰ç»“æœï¼Œå°±ç”Ÿæˆ Excel
        if result_df is not None or len(session.dfs_context) > 0:
            filename = f"Analysis_Report_{uuid.uuid4().hex[:6]}.xlsx"
            file_path = os.path.join(OUTPUT_DIR, filename)
            
            # âœ… è°ƒç”¨æ–°çš„å…¨é‡ä¿å­˜å‡½æ•°
            # ä¼ å…¥ session.dfs_context ä»¥ä¿å­˜æ‰€æœ‰è¢«æ¸…æ´—è¿‡çš„è¡¨
            save_full_context_excel(result_df, session.dfs_context, audit_logger, file_path)
            
            download_link = f"/download/{filename}"
            
            if audit_logger:
                op_count = len([l for l in audit_logger.logs if l['Type']=='Operation'])
                ex_count = len([l for l in audit_logger.logs if l['Type']=='Exclusion'])
                audit_summary = f"ğŸ›¡ï¸ å®¡è®¡è¿½è¸ª: æ‰§è¡Œ {op_count} æ­¥æ“ä½œ, å‰”é™¤ {ex_count} æ¬¡å¼‚å¸¸æ•°æ®ã€‚"

    except Exception as e:
        error_msg = f"ç³»ç»Ÿå¼‚å¸¸: {str(e)}"
        print(f"Server Error: {str(e)}")

    # ==========================================
    # ğŸ¨ å“åº”æ–‡æœ¬æ ¼å¼åŒ– (è§£å†³å­—ä½“è¿‡å¤§é—®é¢˜)
    # ==========================================
    formatted_response = ""
    
    if steps_log:
        formatted_response += "### ğŸ§© æ‰§è¡Œè¿‡ç¨‹\n\n"
        for step in steps_log:
            # å†æ¬¡ç¡®ä¿æ¸…æ´—æ‰ Markdown æ ‡é¢˜ç¬¦
            clean_step = step.replace("#", "").strip()
            formatted_response += f"- {clean_step}\n\n"
        formatted_response += "---\n\n"

    if final_answer:
        formatted_response += "### ğŸ’¡ åˆ†æç»“è®º\n\n"
        # é™çº§æ ‡é¢˜ï¼Œé˜²æ­¢å­—ä½“çˆ†ç‚¸
        lines = final_answer.split('\n')
        clean_lines = []
        for line in lines:
            if line.strip().startswith("#"):
                clean_lines.append(f"**{line.strip('# ')}**")
            else:
                clean_lines.append(line)
        formatted_response += "\n\n".join(clean_lines)
    
    if error_msg:
        formatted_response += f"\n\nğŸš¨ **é”™è¯¯æç¤º**: {error_msg}"
        if not final_answer: formatted_response = error_msg

    return ChatResponse(
        response_text=formatted_response,
        chart_jsons=chart_jsons,
        download_url=download_link,
        audit_summary=audit_summary
    )

@app.get("/download/{filename}")
async def download_file(filename: str):
    file_path = os.path.join(OUTPUT_DIR, filename)
    if os.path.exists(file_path):
        return FileResponse(file_path, filename=filename)
    raise HTTPException(status_code=404, detail="File not found")

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)