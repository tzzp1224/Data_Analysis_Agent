import pandas as pd
from rapidfuzz import process, fuzz
from datetime import datetime
import numpy as np
import json
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# å¼•å…¥æˆ‘ä»¬çš„ LLM å·¥å‚
from app.services.llm_factory import get_llm

# å°è¯•å¯¼å…¥å‘é‡åº“
try:
    from sentence_transformers import SentenceTransformer, util
    HAS_VECTOR_MODEL = True
except ImportError:
    HAS_VECTOR_MODEL = False
    print("âš ï¸ æœªæ£€æµ‹åˆ° sentence-transformersï¼Œå°†ä»…ä½¿ç”¨å­—ç¬¦ä¸²åŒ¹é…æ¨¡å¼ã€‚")

class AuditLogger:
    """å®¡è®¡æ—¥å¿—è®°å½•å™¨"""
    def __init__(self):
        self.logs = []
        self.excluded_data = {}

    def info(self, step_name: str, description: str, affected_rows: int = 0):
        entry = {
            "Timestamp": datetime.now().strftime("%H:%M:%S"),
            "Step": step_name,
            "Description": description,
            "Affected_Rows": affected_rows,
            "Type": "Operation"
        }
        self.logs.append(entry)
        # æ§åˆ¶å°ä¾ç„¶æ‰“å°ç®€ç•¥ç‰ˆï¼Œé˜²æ­¢åˆ·å±
        print(f"ğŸ“ [Audit] {step_name}: {description.splitlines()[0]}... (Rows: {affected_rows})")

    def log_exclusion(self, step_name: str, description: str, excluded_df: pd.DataFrame):
        rows = len(excluded_df)
        entry = {
            "Timestamp": datetime.now().strftime("%H:%M:%S"),
            "Step": step_name,
            "Description": description,
            "Affected_Rows": rows,
            "Type": "Exclusion"
        }
        self.logs.append(entry)
        if rows > 0:
            safe_name = f"{step_name}_{len(self.excluded_data)}"
            self.excluded_data[safe_name] = excluded_df.head(100)
            print(f"ğŸ—‘ï¸ [Audit-Exclusion] {step_name}: Removed {rows} rows.")

    def get_log_df(self):
        return pd.DataFrame(self.logs)

class VectorMatcher:
    """è¯­ä¹‰å‘é‡åŒ¹é…å™¨ (è´Ÿè´£å¬å› Candidates)"""
    _instance = None
    _model = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(VectorMatcher, cls).__new__(cls)
            if HAS_VECTOR_MODEL:
                print("â³ [System] æ­£åœ¨åŠ è½½è¯­ä¹‰å‘é‡æ¨¡å‹ (paraphrase-multilingual)...")
                cls._model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
                print("âœ… æ¨¡å‹åŠ è½½å®Œæ¯•")
        return cls._instance

    def get_candidates(self, source_word: str, target_candidates: list, top_k=5):
        """è¿”å›æœ€ç›¸ä¼¼çš„ Top K ä¸ªå€™é€‰é¡¹"""
        if not self._model: return []
        
        source_emb = self._model.encode(source_word, convert_to_tensor=True)
        target_embs = self._model.encode(target_candidates, convert_to_tensor=True)
        
        cosine_scores = util.cos_sim(source_emb, target_embs)[0]
        
        # è·å– Top K
        k = min(top_k, len(target_candidates))
        top_results = np.argpartition(-cosine_scores.cpu().numpy(), range(k))[:k]
        
        candidates = []
        for idx in top_results:
            score = cosine_scores[idx].item()
            # ğŸ’¡ é™çº§é˜ˆå€¼ï¼šåªè¦æœ‰ä¸€ç‚¹ç‚¹ç›¸å…³(0.1)å°±å¬å›ï¼Œäº¤ç»™ LLM å»åˆ¤æ–­
            if score > 0.1:
                candidates.append((target_candidates[idx], score))
        
        candidates.sort(key=lambda x: x[1], reverse=True)
        return candidates

class LLMJudge:
    """LLM è£åˆ¤ï¼šåˆ©ç”¨å¤§æ¨¡å‹çš„ä¸–ç•ŒçŸ¥è¯†åšæœ€ç»ˆå†³å®š"""
    def __init__(self):
        self.llm = get_llm(temperature=0)
        
    def judge(self, source: str, candidates: list) -> str:
        if not candidates: return None
        
        cand_names = [c[0] if isinstance(c, tuple) or isinstance(c, list) else c for c in candidates]
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """
            ä½ æ˜¯ä¸€ä¸ªå®ä½“å¯¹é½ä¸“å®¶ã€‚
            ä»»åŠ¡ï¼šåˆ¤æ–­å·¦è¾¹çš„ã€æºå®ä½“ã€‘æ˜¯å¦å¯¹åº”å³è¾¹å€™é€‰åˆ—è¡¨ä¸­çš„æŸä¸ªã€æ ‡å‡†å®ä½“ã€‘ã€‚
            
            è§„åˆ™ï¼š
            1. åˆ©ç”¨ä½ çš„ä¸–ç•ŒçŸ¥è¯†ï¼ˆåŒ…æ‹¬ä¸­è‹±æ–‡åã€ç®€ç§°ã€åˆ«åã€æ‹¼éŸ³ã€æ”¶è´­å…³ç³»ï¼‰ã€‚
               ä¾‹å¦‚: "ByteDance" == "å­—èŠ‚è·³åŠ¨", "Meituan" == "ç¾å›¢ç‚¹è¯„", "JD" == "äº¬ä¸œ"ã€‚
            2. å¦‚æœæ‰¾åˆ°äº†ç¡®å®šçš„åŒ¹é…ï¼Œåªè¿”å›è¯¥æ ‡å‡†å®ä½“çš„åç§°ã€‚
            3. å¦‚æœæ‰€æœ‰å€™é€‰éƒ½ä¸åŒ¹é…ï¼Œæˆ–è€…éå¸¸ä¸ç¡®å®šï¼Œè¿”å› "None"ã€‚
            4. åªè¿”å›åç§°å­—ç¬¦ä¸²ï¼Œä¸è¦æœ‰ä»»ä½•æ ‡ç‚¹æˆ–è§£é‡Šã€‚
            """),
            ("human", "æºå®ä½“: '{source}'\nå€™é€‰åˆ—è¡¨: {candidates}")
        ])
        
        try:
            chain = prompt | self.llm | StrOutputParser()
            result = chain.invoke({"source": source, "candidates": str(cand_names)})
            result = result.strip().replace("'", "").replace('"', "")
            
            if result == "None" or result not in cand_names:
                return None
            return result
        except:
            return None

def smart_merge(left_df: pd.DataFrame, right_df: pd.DataFrame, 
                left_on: str, right_on: str, 
                logger: AuditLogger = None) -> pd.DataFrame:
    """
    æ™ºèƒ½ä¸‰çº§åŒ¹é…ï¼šFuzz -> Adaptive LLM
    """
    left_keys = left_df[left_on].astype(str).unique()
    right_keys = right_df[right_on].astype(str).unique()
    
    mapping = {}
    matched_log = []
    
    vector_matcher = VectorMatcher() if HAS_VECTOR_MODEL else None
    llm_judge = LLMJudge()
    
    print(f"ğŸ” [SmartMerge] å¼€å§‹æ™ºèƒ½åŒ¹é… (Left: {len(left_keys)}, Right: {len(right_keys)})")
    
    # ç­–ç•¥é€‰æ‹©
    use_full_llm_match = len(right_keys) <= 50
    if use_full_llm_match:
        print("   ğŸš€ [Strategy] ç›®æ ‡æ•°æ®é‡è¾ƒå°ï¼Œå¯ç”¨ LLM å…¨é‡ç²¾å‡†åŒ¹é…æ¨¡å¼")
    
    for lk in left_keys:
        final_target = None
        method = "None"
        
        # Level 1: Fuzz
        match = process.extractOne(lk, right_keys, scorer=fuzz.WRatio)
        if match:
            target, score, _ = match
            if score >= 90:
                final_target = target
                method = f"Fuzz({int(score)})"
        
        # Level 2: LLM
        if not final_target:
            candidates = []
            if use_full_llm_match:
                candidates = list(right_keys)
            elif vector_matcher:
                candidates = vector_matcher.get_candidates(lk, right_keys, top_k=5)
            
            if candidates:
                llm_choice = llm_judge.judge(lk, candidates)
                if llm_choice:
                    final_target = llm_choice
                    source_type = "FullList" if use_full_llm_match else f"VectorTop{len(candidates)}"
                    method = f"LLM({source_type})"
        
        # è®°å½•
        if final_target:
            mapping[lk] = final_target
            if lk != final_target:
                matched_log.append(f"[{method}] '{lk}' -> '{final_target}'")
        else:
            mapping[lk] = None
            
    # æ‰§è¡Œæ˜ å°„
    temp_col = f"_smart_join_{right_on}"
    left_df_mapped = left_df.copy()
    left_df_mapped[temp_col] = left_df_mapped[left_on].astype(str).map(mapping)
    
    # âœ… ä¿®å¤ç‚¹ï¼šå°†è¯¦ç»†æ—¥å¿—å†™å…¥ Description
    if logger:
        success_count = len([x for x in mapping.values() if x is not None])
        desc = f"æ™ºèƒ½åŒ¹é…: è¾“å…¥ {len(left_keys)} ä¸ªå®ä½“ï¼ŒæˆåŠŸåŒ¹é… {success_count} ä¸ªã€‚"
        
        if matched_log:
            # å°†åŒ¹é…ç»†èŠ‚è¿½åŠ åˆ°æè¿°ä¸­
            detail_str = "\n".join(matched_log)
            desc += f"\n\n--- åŒ¹é…è¯¦æƒ… ({len(matched_log)} æ¡) ---\n{detail_str}"
            
        logger.info("Smart Merge", desc, affected_rows=len(matched_log))
        
        if matched_log:
            print(f"   âœ¨ åŒ¹é…é«˜å…‰æ—¶åˆ»:\n   " + "\n   ".join(matched_log[:5]) + "...")

    # æ‰§è¡Œ Merge
    merged = pd.merge(left_df_mapped, right_df, left_on=temp_col, right_on=right_on, how='left')
    
    if temp_col in merged.columns:
        del merged[temp_col]
        
    return merged