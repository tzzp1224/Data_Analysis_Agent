import pandas as pd
import numpy as np
import sys
import io
import re
import ast
import traceback
import json
from typing import TypedDict, Annotated, List, Literal, Optional, Union, Dict, Any
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langgraph.graph import StateGraph, END
from app.services.llm_factory import get_llm
import operator

# ==========================================
# 0. Âü∫Á°ÄÂ∑•ÂÖ∑
# ==========================================
def clean_code_string(raw_content: Union[str, list, dict]) -> str:
    """Ê∏ÖÊ¥ó‰ª£Á†Å"""
    content = raw_content
    if isinstance(content, list):
        text_parts = []
        for part in content:
            if isinstance(part, dict) and 'text' in part:
                text_parts.append(part['text'])
            elif hasattr(part, 'text'):
                text_parts.append(part.text)
            elif isinstance(part, str):
                text_parts.append(part)
        content = "\n".join(text_parts)
    
    content_str = str(content).strip()
    # Â§ÑÁêÜ repr Â≠óÁ¨¶‰∏≤
    if (content_str.startswith("[") and content_str.endswith("]")) or \
       (content_str.startswith("{") and "text" in content_str):
        try:
            parsed = ast.literal_eval(content_str)
            if isinstance(parsed, list) and len(parsed) > 0:
                return clean_code_string(parsed)
            elif isinstance(parsed, dict):
                return clean_code_string(parsed.get('text', ''))
        except:
            pass
            
    if "text:" in content_str:
        pattern = r"text:\s*(.*?)(?:,\s*extras|\})"
        match = re.search(pattern, content_str, re.DOTALL)
        if match:
            content_str = match.group(1).strip().strip("'").strip('"')

    content_str = content_str.replace("```python", "").replace("```json", "").replace("```", "").strip()
    return content_str

# ==========================================
# 1. ÂÆö‰πâ State
# ==========================================
class AgentState(TypedDict):
    messages: Annotated[List[BaseMessage], operator.add]
    user_instruction: str
    router_decision: str
    error_count: int
    chart_jsons: Annotated[List[str], operator.add]
    # ‚úÖ Êñ∞Â¢ûÔºöÁî®‰∫é‰º†ÈÄíÁîüÊàêÁöÑ Excel Êï∞ÊçÆÂØπË±° (‰∏çÁõ¥Êé•Â≠ò DFÔºåËÄåÊòØÂ≠òÊ†áËÆ∞ÔºåÂÆûÈôÖÊï∞ÊçÆÂú® context ‰∏≠ÊµÅËΩ¨)
    # ËøôÈáåÊàë‰ª¨ÁÆÄÂåñÔºöÊï∞ÊçÆÈÄöËøá return Â≠óÂÖ∏‰º†ÂõûÔºåÂú® main ‰∏≠Â§ÑÁêÜ
    reply: str

# ==========================================
# 2. ‰ª£Á†ÅÊâßË°åÂô® (ÊîØÊåÅ result_df ÊçïËé∑)
# ==========================================
def execute_code(dfs: Dict[str, pd.DataFrame], code: str) -> dict:
    import plotly.graph_objects as go
    import plotly.express as px
    
    local_vars = {"dfs": dfs, "pd": pd, "np": np, "px": px, "go": go}
    if len(dfs) > 0:
        local_vars['df'] = dfs[list(dfs.keys())[0]]

    old_stdout = sys.stdout
    redirected_output = io.StringIO()
    sys.stdout = redirected_output
    
    captured_figs = []
    generated_df = None # Áî®‰∫éÂ≠òÂÇ® result_df
    
    try:
        clean_code = clean_code_string(code)
        if not clean_code: 
            return {"success": True, "dfs": dfs, "chart_jsons": [], "log": "Êó†‰ª£Á†Å", "result_df": None}

        exec(clean_code, {}, local_vars)
        
        # 1. ÊçïËé∑ÂõæË°®
        for var_name, var_val in local_vars.items():
            if var_name.startswith("fig") and hasattr(var_val, "to_json"):
                captured_figs.append(var_val.to_json())
        
        # 2. ‚úÖ Ê†∏ÂøÉÂçáÁ∫ßÔºöÊçïËé∑ result_df
        # Â¶ÇÊûú LLM ÁîüÊàê‰∫Ü result_dfÔºåËØ¥ÊòéÂÆÉÊÉ≥ËæìÂá∫Êñá‰ª∂
        if "result_df" in local_vars:
            obj = local_vars["result_df"]
            if isinstance(obj, pd.DataFrame):
                print("üíæ [System] ÊçïËé∑Âà∞ÁªìÊûúÊï∞ÊçÆ: result_df")
                generated_df = obj
        
        return {
            "success": True,
            "dfs": local_vars["dfs"],
            "chart_jsons": captured_figs,
            "result_df": generated_df, # ËøîÂõûËøô‰∏™ÂØπË±°
            "log": redirected_output.getvalue()
        }
    except Exception:
        error_trace = traceback.format_exc()
        return {
            "success": False,
            "dfs": dfs,
            "chart_jsons": [],
            "result_df": None,
            "log": f"‚ùå Runtime Error:\n{error_trace}"
        }
    finally:
        sys.stdout = old_stdout

# ==========================================
# 3. Nodes
# ==========================================

def supervisor_node(state: AgentState, dfs_context: dict):
    instruction = state.get("user_instruction", "")
    messages = state.get("messages", [])
    
    if messages:
        last_msg = messages[-1]
        if isinstance(last_msg, HumanMessage) and "WORKER_DONE" in str(last_msg.content):
            return {"router_decision": "end"}

    if not instruction and len(messages) == 0:
        return {"router_decision": "auto_eda"}
        
    llm = get_llm(temperature=0)
    file_list_str = ", ".join(dfs_context.keys())
    
    system_prompt = """‰Ω†ÊòØ‰∏Ä‰∏™Êï∞ÊçÆÊìç‰ΩúÁ≥ªÁªüÁöÑÊåáÊå•ÂÆò„ÄÇ
    ÂΩìÂâçÊñá‰ª∂: [{file_list}]
    
    Ê†πÊçÆÊåá‰ª§ÂÜ≥ÂÆöÔºö
    1. 'python_worker': ÈúÄË¶ÅÊìç‰ΩúÊï∞ÊçÆÔºàÂêàÂπ∂„ÄÅÁ≠õÈÄâ„ÄÅËÆ°ÁÆó„ÄÅÁîªÂõæ„ÄÅËæìÂá∫Êñ∞Ë°®Ê†ºÔºâ„ÄÇ
    2. 'general_chat': Êó†ÂÖ≥Êåá‰ª§„ÄÇ
    3. 'end': ÁªìÊùü„ÄÇ
    
    ËøîÂõû JSON: {{ "decision": "...", "reason": "..." }}
    """
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "Êåá‰ª§: {instruction}\nÂéÜÂè≤: {history}")
    ])
    
    chain = prompt | llm | StrOutputParser()
    response = chain.invoke({
        "instruction": str(instruction), 
        "history": str(messages[-2:]),
        "file_list": file_list_str
    })
    
    try:
        import json
        clean_resp = clean_code_string(response)
        json_match = re.search(r"\{.*\}", clean_resp, re.DOTALL)
        if json_match: clean_resp = json_match.group()
        res_json = json.loads(clean_resp)
        decision = res_json.get("decision", "general_chat")
        
        if decision == "python_worker": return {"router_decision": "python_worker"}
        if decision == "general_chat": 
            return {"router_decision": "general_chat", "reply": res_json.get("reason", "Êó†Ê≥ïÂ§ÑÁêÜ")}
        return {"router_decision": "end"}
    except:
        return {"router_decision": "general_chat", "reply": "Êåá‰ª§Ëß£ÊûêÂ§±Ë¥•„ÄÇ"}

def general_chat_node(state: AgentState):
    return {"messages": [AIMessage(content=state.get("reply", "Êó†Ê≥ïÂ§ÑÁêÜ„ÄÇ"))]}

def python_worker_node(state: AgentState, dfs_context: dict, mode: str = "custom"):
    """
    ÂÖ®ËÉΩÂûã Python ‰ª£Á†ÅÁîüÊàêËäÇÁÇπ„ÄÇ
    
    Args:
        state: LangGraph Áä∂ÊÄÅ
        dfs_context: ÂåÖÂê´ÊâÄÊúâ DataFrame ÁöÑÂ≠óÂÖ∏ {'filename': df}
        mode: 'custom' (ÂìçÂ∫îÁî®Êà∑Êåá‰ª§) | 'auto_eda' (Ëá™Âä®Êé¢Á¥¢)
    """
    dfs = dfs_context
    messages = state['messages']
    instruction = state.get('user_instruction', '')
    
    # ---------------------------------------------------------
    # 1. ÊûÑÂª∫Êï∞ÊçÆÂÖ®ÊôØ (Schema Context)
    # ---------------------------------------------------------
    # Êàë‰ª¨Âè™Áªô LLM ÁúãÂàóÂêç„ÄÅÁ±ªÂûãÂíåÂâç5Ë°åÔºåÁªù‰∏ç‰º†ËæìÂÖ®ÈáèÊï∞ÊçÆÔºåËäÇÁúÅ Token
    schema_info = ""
    for name, df in dfs.items():
        buffer = io.StringIO()
        df.info(buf=buffer)
        info_str = buffer.getvalue()
        head_str = df.head().to_string()
        schema_info += f"\n=== File: {name} ===\n[Info]:\n{info_str}\n[Head (First 5 rows)]:\n{head_str}\n"
    
    # ---------------------------------------------------------
    # 2. Ëé∑ÂèñÈîôËØØ‰∏ä‰∏ãÊñá (Self-Healing)
    # ---------------------------------------------------------
    # Ê£ÄÊü•‰∏ä‰∏ÄÊù°Ê∂àÊÅØÊòØÂê¶ÊòØ Executor ËøîÂõûÁöÑÊä•Èîô
    last_message = messages[-1] if messages else None
    error_context = "Êó†"
    if isinstance(last_message, HumanMessage) and "‚ùå Runtime Error" in str(last_message.content):
        error_context = f"‚ö†Ô∏è ‰∏ä‰∏ÄÊ¨°‰ª£Á†ÅÊâßË°åÊä•ÈîôÔºåËØ∑Ê†πÊçÆ‰ª•‰∏ã Traceback ‰øÆÊ≠£‰ª£Á†Å:\n{last_message.content}"
    
    # ---------------------------------------------------------
    # 3. ÂÆö‰πâÊ†∏ÂøÉ System Prompt (Ê§çÂÖ•ÂõõÂ§ßÂ±ÇÁ∫ßËÉΩÂäõ)
    # ---------------------------------------------------------
    llm = get_llm(temperature=0)
    
    system_instructions = """
    ‰Ω†ÊòØ‰∏Ä‰∏™ÂÖ®ËÉΩÂûã Python Êï∞ÊçÆÂàÜÊûê‰∏ìÂÆ∂„ÄÇ‰Ω†Êã•ÊúâÂØπ `dfs` Â≠óÂÖ∏ÁöÑÂÆåÂÖ®ËÆøÈóÆÊùÉÈôêÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∫ÜÁî®Êà∑‰∏ä‰º†ÁöÑÊâÄÊúâÊï∞ÊçÆË°®„ÄÇ
    
    ‰Ω†ÁöÑÊ†∏ÂøÉËÉΩÂäõÂ±ÇÁ∫ßÂ¶Ç‰∏ãÔºåËØ∑Ê†πÊçÆÁî®Êà∑Êåá‰ª§ÁÅµÊ¥ªË∞ÉÁî®Ôºö
    
    üîç **L1: Êï∞ÊçÆÊ∏ÖÊ¥ó‰∏éÈ¢ÑÂ§ÑÁêÜ (Preprocessing)**
       - **Ê†ºÂºèÁªü‰∏Ä**Ôºö‰ΩøÁî® `pd.to_datetime`, `astype` ËΩ¨Êç¢Ê∑∑‰π±ÁöÑÊ†ºÂºè„ÄÇ
       - **ÊñáÊú¨Ê∏ÖÊ¥ó**Ôºö‰ΩøÁî® `.str.strip()`, `.str.replace()` ÂéªÈô§Âπ≤Êâ∞Â≠óÁ¨¶„ÄÇ
       - **ÂºÇÂ∏∏Â§ÑÁêÜ**Ôºö‰ΩøÁî® `fillna` Â°´ÂÖÖÁº∫Â§±ÂÄºÔºåÊàñ `dropna` Âà†Èô§Êó†ÊïàË°å„ÄÇ
       - **Ê®°Á≥äËØ≠‰πâ**ÔºöÂ¶ÇÊûúÁî®Êà∑ËØ¥ÁöÑÂàóÂêç‰∏éÂÆûÈôÖ‰∏çÂÆåÂÖ®‰∏ÄËá¥ÔºàÂ¶Ç "ÈáëÈ¢ù" vs "Amount"ÔºâÔºåËØ∑Ê†πÊçÆËØ≠‰πâËá™Âä®Êé®Êñ≠„ÄÇ
       
    üîó **L2: Â§öË°®ÂÖ≥ËÅî‰∏éÊï¥Âêà (Integration)**
       - **ÂÖ≥ËÅî**Ôºö‰ΩøÁî® `pd.merge` (Á±ª‰ºº VLOOKUP) ËøõË°åÊï∞ÊçÆÂåπÈÖç„ÄÇ
       - **ËøΩÂä†**Ôºö‰ΩøÁî® `pd.concat` ÂêàÂπ∂ÁªìÊûÑÁõ∏ÂêåÁöÑË°®„ÄÇ
       - **Ê≥®ÊÑè**ÔºöÂêàÂπ∂ÂâçËØ∑Á°Æ‰øù Key ÂàóÁöÑÁ±ªÂûã‰∏ÄËá¥„ÄÇ
       
    üìä **L3: ÁªüËÆ°‰∏éÈÄèËßÜ (Analysis)**
       - **ËÅöÂêà**Ôºö‰ΩøÁî® `groupby`, `pivot_table` ËøõË°åÂ§öÁª¥Â∫¶Ê±áÊÄª„ÄÇ
       - **ËÆ°ÁÆó**ÔºöËÆ°ÁÆóÂç†ÊØî„ÄÅÂ¢ûÈïøÁéá„ÄÅÁªüËÆ°ÂàÜÂ∏É„ÄÇ
       
    üìà **L4: ÂèØËßÜÂåñ‰∏é‰∫§‰ªò (Delivery)**
       - **Êñá‰ª∂‰∫§‰ªò (‰∏•Ê†ºÈôêÂà∂)**Ôºö
         - Âè™ÊúâÂΩìÁî®Êà∑**ÊòéÁ°ÆË¶ÅÊ±Ç**‚ÄúÂØºÂá∫‚Äù„ÄÅ‚Äú‰øùÂ≠ò‚Äù„ÄÅ‚Äú‰∏ãËΩΩ‚Äù„ÄÅ‚ÄúÁîüÊàêÊñ∞Ë°®‚ÄùÊàñ‚ÄúËæìÂá∫Êñá‰ª∂‚ÄùÊó∂ÔºåÊâçÂ∞ÜÁªìÊûú DataFrame ËµãÂÄºÁªôÂèòÈáè `result_df`„ÄÇ
         - Â¶ÇÊûúÁî®Êà∑Âè™ÊòØÈóÆ‚ÄúÊòØ‰ªÄ‰πà‚Äù„ÄÅ‚ÄúÂàÜÊûê‰∏Ä‰∏ã‚Äù„ÄÅ‚ÄúÁªüËÆ°‰∏Ä‰∏ã‚ÄùÔºå**‰∏çË¶Å**ËµãÂÄºÁªô `result_df`ÔºåÁõ¥Êé• `print` ÊâìÂç∞ÁªìÊûúÂç≥ÂèØ„ÄÇ
       - **ÂèØËßÜÂåñ**Ôºö‰ΩøÁî® `plotly.express` (px) ÁªòÂà∂‰∫§‰∫íÂºèÂõæË°®ÔºåÂπ∂Â∞ÜÂõæË°®ÂØπË±°ËµãÂÄºÁªô `fig` (Êàñ fig1, fig2)„ÄÇ
    
    „ÄêËæìÂá∫ËßÑËåÉ - ÈùûÂ∏∏ÈáçË¶Å„Äë
    ‰Ω†ÁöÑ‰ª£Á†ÅËæìÂá∫ÂøÖÈ°ªÂåÖÂê´‰ª•‰∏ã‰∏âÈÉ®ÂàÜÔºàÈÄöËøá `print` ËæìÂá∫ÔºâÔºö
    1. **# PLAN**: ÁÆÄÂçïÊ≥®ÈáäÔºåËØ¥Êòé‰Ω†ÊâìÁÆóÂÅö‰ªÄ‰πà„ÄÇ
    2. **# CODE**: ÊâßË°åÁöÑÂÖ∑‰Ωì‰ª£Á†Å„ÄÇ
    3. **# INSIGHTS**: **(Ê†∏ÂøÉË¶ÅÊ±Ç)** ‰ª£Á†ÅÊâßË°åÂÆåÂêéÔºåÂøÖÈ°ª‰ΩøÁî® `print` ËæìÂá∫‰∏ÄÊÆµ**Ëá™ÁÑ∂ËØ≠Ë®ÄÁöÑÂàÜÊûêÁªìËÆ∫**„ÄÇ
       - Â¶ÇÊûúÊòØÁîªÂõæÔºåËØ∑Ëß£ÈáäÂõæË°®Â±ïÁ§∫‰∫Ü‰ªÄ‰πàË∂ãÂäøÔºà‰æãÂ¶ÇÔºö‚Äú‰ªéÂõæË°®ÂèØËßÅÔºåP001ÈîÄÈáèÂú®5ÊúàËææÂà∞È°∂Â≥∞...‚ÄùÔºâ„ÄÇ
       - Â¶ÇÊûúÊòØÊï∞ÊçÆÂ§ÑÁêÜÔºåËØ∑Ê±áÊä•Â§ÑÁêÜÁªìÊûúÔºà‰æãÂ¶ÇÔºö‚ÄúÂ∑≤ÊàêÂäüÂêàÂπ∂‰∏§Âº†Ë°®ÔºåÂÖ±ÁîüÊàê 500 Ë°åÊï∞ÊçÆ...‚ÄùÔºâ„ÄÇ
       - ‰∏çË¶ÅÂè™ÁªôÂÜ∑ÂÜ∞ÂÜ∞ÁöÑÊï∞Â≠óÊàñÂõæË°®ÔºåË¶ÅÁªô‚ÄúÊ¥ûÂØü‚Äù„ÄÇ

    „Äê‰ª£Á†ÅÁºñÂÜôËßÑËåÉ„Äë
    1. **Êï∞ÊçÆËÆøÈóÆ**ÔºöÁõ¥Êé•‰ΩøÁî® `dfs['filename']` ËØªÂèñÊï∞ÊçÆ„ÄÇ**‰∏•Á¶Å**‰ΩøÁî® `pd.read_excel` Êàñ `pd.read_csv`„ÄÇ
    2. **ÂèØËß£ÈáäÊÄß**ÔºöÂú®ÁºñÂÜô‰ª£Á†ÅÂâçÔºåÂøÖÈ°ªÂÖàÂÜô‰∏ÄÊÆµ Python Ê≥®Èáä (`# PLAN: ...`)ÔºåÁî®Ëá™ÁÑ∂ËØ≠Ë®ÄËß£Èáä‰Ω†ÁöÑËß£È¢òÊÄùË∑Ø„ÄÇ
    3. **ÁªìÊùü‰ø°Âè∑**Ôºö‰ªªÂä°ÂÆåÊàêÂêéÔºåÂøÖÈ°ªÊâìÂç∞ `print("WORKER_DONE")`„ÄÇ
    4. **Á¶ÅÊ≠¢**ÔºöÁ¶ÅÊ≠¢‰ΩøÁî® `to_excel` ‰øùÂ≠òÊñá‰ª∂ÔºàÁ≥ªÁªü‰ºöËá™Âä®Êé•ÁÆ° `result_df` ËøõË°å‰øùÂ≠òÔºâ„ÄÇÁ¶ÅÊ≠¢‰ΩøÁî® `plt.show()`„ÄÇ
    """
    
    # ---------------------------------------------------------
    # 4. Ê†πÊçÆÊ®°ÂºèË∞ÉÊï¥Êåá‰ª§
    # ---------------------------------------------------------
    if mode == "auto_eda":
        # Ë¶ÜÁõñÁî®Êà∑Êåá‰ª§ÔºåÂº∫Âà∂ÊâßË°å EDA
        specific_task = """
        „ÄêÂΩìÂâç‰ªªÂä°ÔºöËá™Âä® EDA„Äë
        Áî®Êà∑Êú™ËæìÂÖ•Êåá‰ª§„ÄÇËØ∑ÂØπÊï∞ÊçÆËøõË°åÂü∫Á°ÄÊ¶ÇËßàÔºö
        1. ÊâìÂç∞ÊØè‰∏™Ë°®ÁöÑÂü∫Êú¨ÂΩ¢Áä∂ÂíåÁº∫Â§±ÂÄºÁªüËÆ°„ÄÇ
        2. ÊåëÈÄâÊúÄÊúâÂàÜÊûê‰ª∑ÂÄºÁöÑÊï∞ÂÄºÂàóÊàñÂàÜÁ±ªÂàóÔºå‰ΩøÁî® Plotly ÁªòÂà∂ **Ëá≥Â∞ë‰∏§Âº†** ÂõæË°® (ËµãÂÄºÁªô fig1, fig2)„ÄÇ
        3. ÊâìÂç∞ "WORKER_DONE"„ÄÇ
        """
        instruction_to_send = "ËØ∑ËøõË°åËá™Âä® EDA ÂàÜÊûê„ÄÇ"
    else:
        # Ê≠£Â∏∏ÂìçÂ∫îÁî®Êà∑Êåá‰ª§
        specific_task = f"""
        „ÄêÂΩìÂâç‰ªªÂä°„Äë
        Áî®Êà∑Êåá‰ª§: {instruction}
        ËØ∑Ê†πÊçÆÊåá‰ª§ÈÄªËæëÔºåÁºñÂÜôÁõ∏Â∫îÁöÑ Pandas/Plotly ‰ª£Á†Å„ÄÇ
        Â¶ÇÊûúÊ∂âÂèäÊñá‰ª∂ËæìÂá∫ÔºåËÆ∞ÂæóËµãÂÄºÁªô `result_df`„ÄÇ
        """
        instruction_to_send = instruction

    # ---------------------------------------------------------
    # 5. ÁªÑË£Ö Prompt Âπ∂Ë∞ÉÁî®
    # ---------------------------------------------------------
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_instructions + "\n" + specific_task + "\nËØ∑Âè™ËøîÂõûÁ∫Ø Python ‰ª£Á†ÅÔºå‰∏çË¶ÅÂåÖÂê´ Markdown Ê†áËÆ∞ (```python)„ÄÇ"),
        ("human", """
        „ÄêÊï∞ÊçÆÂÖ®ÊôØ (Schema)„Äë
        {schema}
        
        „ÄêÁî®Êà∑Êåá‰ª§„Äë
        {instruction}
        
        „ÄêÈîôËØØÂèçÈ¶à (Self-Correction)„Äë
        {error_context}
        """)
    ])
    
    # Ë∞ÉÁî® LLM
    response = (prompt | llm).invoke({
        "schema": schema_info,
        "instruction": instruction_to_send,
        "error_context": error_context
    })
    
    return {"messages": [response]}

def executor_node(state: AgentState, dfs_context: dict):
    messages = state['messages']
    code = messages[-1].content
    print(f"\n‚ö° ÊâßË°å‰ª£Á†Å:\n{clean_code_string(code)[:80]}...")
    
    result = execute_code(dfs_context, code)
    
    updates = {}
    if result['success']:
        updates["error_count"] = 0
        if result['chart_jsons']:
            updates["chart_jsons"] = result['chart_jsons']
        
        # ‚úÖ Â§ÑÁêÜÁªìÊûúÊï∞ÊçÆ
        if result['result_df'] is not None:
            # Êàë‰ª¨Â∞ÜÁªìÊûú DF ÊöÇÂ≠òÂÖ• context ÁöÑ‰∏Ä‰∏™ÁâπÊÆä keyÔºåÊàñËÄÖÈÄöËøá updates ËøîÂõû
            # ‰∏∫‰∫ÜÁÆÄÂçïÔºåÊàë‰ª¨Âú® main.py ÈáåÈÄöËøáÁõëÂê¨ updates Êãø‰∏çÂà∞ÂØπË±°ÔºàState‰∏çËÉΩÂ≠òDFÔºâ
            # ÊâÄ‰ª•Êàë‰ª¨Êää result_df ÊîæÂÖ• dfs_context ÁöÑ‰∏Ä‰∏™ÁâπÊÆäÊßΩ‰ΩçÔºå‰æõ Main ËØªÂèñ
            dfs_context['__last_result_df__'] = result['result_df']
            
            # Âπ∂Âú®Ê∂àÊÅØÈáåÊ†áËÆ∞ÔºåÈÄöÁü•ÂâçÁ´Ø
            log = result['log'] + "\n[System] Â∑≤ÁîüÊàêÁªìÊûúË°®Ê†º (result_df)ÔºåÂáÜÂ§áÂØºÂá∫„ÄÇ"
        else:
            log = result['log']
            
        if "WORKER_DONE" in log or "WORKER_DONE" in code:
             updates["messages"] = [HumanMessage(content=f"‚úÖ ÊàêÂäü:\n{log}\n(Signal: WORKER_DONE)")]
        else:
             updates["messages"] = [HumanMessage(content=f"‚úÖ ÊàêÂäü:\n{log}")]
    else:
        updates["messages"] = [HumanMessage(content=result['log'])]
        updates["error_count"] = state.get("error_count", 0) + 1
        
    return updates

# ==========================================
# 4. ÊûÑÂª∫ Graph
# ==========================================
def router_logic(state: AgentState):
    decision = state.get("router_decision")
    error_count = state.get("error_count", 0)
    messages = state.get("messages", [])
    if messages and error_count > 0:
        if error_count > 3: return END
        return 'python_worker'
    if decision == 'python_worker': return 'python_worker'
    if decision == 'auto_eda': return 'auto_eda'
    if decision == 'general_chat': return 'general_chat'
    return END

def executor_router(state: AgentState):
    messages = state.get("messages", [])
    if not messages: return "supervisor"
    last_content = str(messages[-1].content)
    if "‚ùå Runtime Error" in last_content: return "retry"
    if "WORKER_DONE" in last_content: return "end"
    return "continue"

def create_workflow(dfs_context: dict):
    from functools import partial
    workflow = StateGraph(AgentState)
    workflow.add_node("supervisor", partial(supervisor_node, dfs_context=dfs_context))
    workflow.add_node("general_chat", general_chat_node)
    workflow.add_node("python_worker", partial(python_worker_node, dfs_context=dfs_context, mode='custom'))
    workflow.add_node("auto_eda", partial(python_worker_node, dfs_context=dfs_context, mode='auto_eda'))
    workflow.add_node("executor", partial(executor_node, dfs_context=dfs_context))
    
    workflow.set_entry_point("supervisor")
    workflow.add_conditional_edges("supervisor", router_logic, {"python_worker": "python_worker", "auto_eda": "auto_eda", "general_chat": "general_chat", END: END})
    workflow.add_edge("auto_eda", "executor")
    workflow.add_edge("python_worker", "executor")
    workflow.add_conditional_edges("executor", executor_router, {"retry": "python_worker", "end": END, "continue": "python_worker", "supervisor": "supervisor"})
    workflow.add_edge("general_chat", END)
    return workflow.compile()