import pandas as pd
import numpy as np
import sys
import io
import re
import ast
import traceback
import json
import warnings # 
from typing import TypedDict, Annotated, List, Literal, Optional, Union, Dict, Any
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langgraph.graph import StateGraph, END
from app.services.llm_factory import get_llm
import operator
from app.utils.tools import AuditLogger, smart_merge

# ==========================================
# 0. åŸºç¡€å·¥å…·
# ==========================================
def clean_code_string(raw_content: Union[str, list, dict]) -> str:
    """æ¸…æ´—ä»£ç """
    content = raw_content
    if isinstance(content, list):
        text_parts = []
        for part in content:
            if isinstance(part, dict) and 'text' in part:
                text_parts.append(part['text'])
            elif hasattr(part, 'text'):
                text_parts.append(part.text)
            elif isinstance(part, str):
                text_parts.append(part)
        content = "\n".join(text_parts)
    
    content_str = str(content).strip()
    # å¤„ç† repr å­—ç¬¦ä¸²
    if (content_str.startswith("[") and content_str.endswith("]")) or \
       (content_str.startswith("{") and "text" in content_str):
        try:
            parsed = ast.literal_eval(content_str)
            if isinstance(parsed, list) and len(parsed) > 0:
                return clean_code_string(parsed)
            elif isinstance(parsed, dict):
                return clean_code_string(parsed.get('text', ''))
        except:
            pass
            
    if "text:" in content_str:
        pattern = r"text:\s*(.*?)(?:,\s*extras|\})"
        match = re.search(pattern, content_str, re.DOTALL)
        if match:
            content_str = match.group(1).strip().strip("'").strip('"')

    content_str = content_str.replace("```python", "").replace("```json", "").replace("```", "").strip()
    return content_str

# ==========================================
# 1. å®šä¹‰ State
# ==========================================
class AgentState(TypedDict):
    messages: Annotated[List[BaseMessage], operator.add]
    user_instruction: str
    router_decision: str
    error_count: int
    chart_jsons: Annotated[List[str], operator.add]
    # âœ… æ–°å¢ï¼šç”¨äºä¼ é€’ç”Ÿæˆçš„ Excel æ•°æ®å¯¹è±¡ (ä¸ç›´æ¥å­˜ DFï¼Œè€Œæ˜¯å­˜æ ‡è®°ï¼Œå®é™…æ•°æ®åœ¨ context ä¸­æµè½¬)
    # è¿™é‡Œæˆ‘ä»¬ç®€åŒ–ï¼šæ•°æ®é€šè¿‡ return å­—å…¸ä¼ å›ï¼Œåœ¨ main ä¸­å¤„ç†
    reply: str

# ==========================================
# 2. ä»£ç æ‰§è¡Œå™¨ (æ”¯æŒ result_df æ•è·)
# ==========================================
def execute_code(dfs: Dict[str, pd.DataFrame], code: str) -> dict:
    import plotly.graph_objects as go
    import plotly.express as px
    import traceback
    import io
    
    # âœ… 1. å¯¼å…¥æ‰€æœ‰å·¥å…· (ç¡®ä¿ tools.py é‡Œæœ‰ smart_reconcile)
    from app.utils.tools import AuditLogger, smart_merge, smart_reconcile
    
    audit = AuditLogger()
    
    # âœ… 2. å®šä¹‰åŒ…è£…å™¨ (Wrappers)
    # Smart Merge åŒ…è£…å™¨
    def smart_merge_wrapper(left, right, left_on, right_on, threshold=None):
        return smart_merge(left, right, left_on, right_on, logger=audit)

    # âœ… Smart Reconcile åŒ…è£…å™¨ (å…³é”®ï¼)
    def smart_reconcile_wrapper(df_sys, df_bank, sys_key, bank_key, sys_amount, bank_amount, tolerance=0.01):
        return smart_reconcile(df_sys, df_bank, sys_key, bank_key, sys_amount, bank_amount, tolerance, logger=audit)

    # âœ… æ–°å¢ï¼šå®šä¹‰è¿˜åŸå‡½æ•°
    def reload_data_wrapper(filename: str):
        backup_key = f"__backup_{filename}"
        if backup_key in dfs:
            print(f"ğŸ”„ [System] æ­£åœ¨è¿˜åŸæ•°æ®: {filename}")
            # ä»å¤‡ä»½ä¸­æ¢å¤ï¼Œå¹¶ç¡®ä¿æ˜¯æ·±æ‹·è´
            dfs[filename] = dfs[backup_key].copy(deep=True)
            return True
        else:
            print(f"âŒ [System] æœªæ‰¾åˆ°å¤‡ä»½æ•°æ®: {filename}")
            return False
        
    # âœ… 3. æ³¨å…¥åˆ°å±€éƒ¨å˜é‡
    local_vars = {
        "dfs": dfs, 
        "pd": pd, 
        "np": np, 
        "px": px, 
        "go": go,
        "audit": audit,
        "smart_merge": smart_merge_wrapper,       # L2 å·¥å…·
        "smart_reconcile": smart_reconcile_wrapper, # L3 å·¥å…· (å¿…é¡»æ³¨å…¥ï¼)
        "reload_data": reload_data_wrapper
    }
    
    if len(dfs) > 0:
        local_vars['df'] = dfs[list(dfs.keys())[0]]

    old_stdout = sys.stdout
    redirected_output = io.StringIO()
    sys.stdout = redirected_output
    
    captured_figs = []
    generated_df = None
    
    try:
        clean_code = clean_code_string(code)
        if not clean_code: 
            return {"success": True, "dfs": dfs, "chart_jsons": [], "log": "æ— ä»£ç ", "result_df": None, "audit_logger": audit}

        # âœ… ä¿®å¤ç‚¹ï¼šå¼ºåˆ¶æ³¨å…¥å±è”½è­¦å‘Šçš„ä»£ç ï¼Œé˜²æ­¢ SettingWithCopyWarning æ±¡æŸ“æ§åˆ¶å°
        # è¿™å¯ä»¥é˜²æ­¢ Agent è¢«æ— å®³çš„è­¦å‘Šè¿·æƒ‘ï¼Œå¯¼è‡´æ­»å¾ªç¯
        safe_code = "import warnings\nwarnings.filterwarnings('ignore')\n" + clean_code
        
        # æ‰§è¡Œä»£ç 
        exec(safe_code, {}, local_vars)
        
        # æ•è·ç»“æœ
        for var_name, var_val in local_vars.items():
            if var_name.startswith("fig") and hasattr(var_val, "to_json"):
                captured_figs.append(var_val.to_json())
        
        if "result_df" in local_vars:
            obj = local_vars["result_df"]
            if isinstance(obj, pd.DataFrame):
                print("ğŸ’¾ [System] æ•è·åˆ°ç»“æœæ•°æ®: result_df")
                generated_df = obj
        
        return {
            "success": True,
            "dfs": local_vars["dfs"],
            "chart_jsons": captured_figs,
            "result_df": generated_df,
            "audit_logger": audit, 
            "log": redirected_output.getvalue()
        }
    except Exception:
        error_trace = traceback.format_exc()
        return {
            "success": False,
            "dfs": dfs,
            "chart_jsons": [],
            "result_df": None,
            "audit_logger": audit,
            "log": f"âŒ Runtime Error:\n{error_trace}" # å°†æŠ¥é”™ç”©å›ç»™ Agent
        }
    finally:
        sys.stdout = old_stdout

# ==========================================
# 3. Nodes
# ==========================================

def supervisor_node(state: AgentState, dfs_context: dict):
    instruction = state.get("user_instruction", "")
    messages = state.get("messages", [])
    
    # âœ… æ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
    if messages:
        last_msg = messages[-1]
        if isinstance(last_msg, HumanMessage):
             content = str(last_msg.content)
             # åªè¦æ£€æµ‹åˆ° WORKER_DONE æˆ– æ˜ç¡®çš„åˆ†æç»“è®ºï¼Œå°±ç»“æŸ
             if "WORKER_DONE" in content:
                 return {"router_decision": "end"}

    if not instruction and len(messages) == 0:
        return {"router_decision": "auto_eda"}
        
    llm = get_llm(temperature=0)
    file_list_str = ", ".join(dfs_context.keys())
    
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ•°æ®æ“ä½œç³»ç»Ÿçš„æŒ‡æŒ¥å®˜ã€‚
    å½“å‰æ–‡ä»¶: [{file_list}]
    
    æ ¹æ®æŒ‡ä»¤å†³å®šï¼š
    1. 'python_worker': éœ€è¦æ“ä½œæ•°æ®ï¼ˆåˆå¹¶ã€ç­›é€‰ã€è®¡ç®—ã€ç”»å›¾ã€è¾“å‡ºæ–°è¡¨æ ¼ï¼‰ã€‚
    2. 'general_chat': æ— å…³æŒ‡ä»¤ã€‚
    3. 'end': ç»“æŸã€‚
    
    è¿”å› JSON: {{ "decision": "...", "reason": "..." }}
    """
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "æŒ‡ä»¤: {instruction}\nå†å²: {history}")
    ])

    # ç®€å•çš„å®¹é”™æœºåˆ¶ï¼Œé˜²æ­¢ supervisor æ­»å¾ªç¯
    if len(messages) > 10:
        return {"router_decision": "end"}
    
    chain = prompt | llm | StrOutputParser()
    response = chain.invoke({
        "instruction": str(instruction), 
        "history": str(messages[-2:]),
        "file_list": file_list_str
    })
    
    try:
        import json
        clean_resp = clean_code_string(response)
        json_match = re.search(r"\{.*\}", clean_resp, re.DOTALL)
        if json_match: clean_resp = json_match.group()
        res_json = json.loads(clean_resp)
        decision = res_json.get("decision", "general_chat")
        
        if decision == "python_worker": return {"router_decision": "python_worker"}
        if decision == "general_chat": 
            return {"router_decision": "general_chat", "reply": res_json.get("reason", "æ— æ³•å¤„ç†")}
        return {"router_decision": "end"}
    except:
        return {"router_decision": "general_chat", "reply": "æŒ‡ä»¤è§£æå¤±è´¥ã€‚"}

def general_chat_node(state: AgentState):
    return {"messages": [AIMessage(content=state.get("reply", "æ— æ³•å¤„ç†ã€‚"))]}

def python_worker_node(state: AgentState, dfs_context: dict, mode: str = "custom"):
    """
    å…¨èƒ½å‹ Python ä»£ç ç”ŸæˆèŠ‚ç‚¹ã€‚
    
    Args:
        state: LangGraph çŠ¶æ€
        dfs_context: åŒ…å«æ‰€æœ‰ DataFrame çš„å­—å…¸ {'filename': df}
        mode: 'custom' (å“åº”ç”¨æˆ·æŒ‡ä»¤) | 'auto_eda' (è‡ªåŠ¨æ¢ç´¢)
    """
    dfs = dfs_context
    messages = state['messages']
    instruction = state.get('user_instruction', '')
    
    # ---------------------------------------------------------
    # 1. æ„å»ºæ•°æ®å…¨æ™¯ (Schema Context)
    # ---------------------------------------------------------
    # æˆ‘ä»¬åªç»™ LLM çœ‹åˆ—åã€ç±»å‹å’Œå‰5è¡Œï¼Œç»ä¸ä¼ è¾“å…¨é‡æ•°æ®ï¼ŒèŠ‚çœ Token
    schema_info = ""
    for name, df in dfs.items():
        if name.startswith("__"): continue
        buffer = io.StringIO()
        df.info(buf=buffer)
        info_str = buffer.getvalue()
        head_str = df.head().to_string()
        schema_info += f"\n=== File: {name} ===\n[Info]:\n{info_str}\n[Head (First 5 rows)]:\n{head_str}\n"
    
    # ---------------------------------------------------------
    # 2. è·å–é”™è¯¯ä¸Šä¸‹æ–‡ (Self-Healing)
    # ---------------------------------------------------------
    # æ£€æŸ¥ä¸Šä¸€æ¡æ¶ˆæ¯æ˜¯å¦æ˜¯ Executor è¿”å›çš„æŠ¥é”™
    last_message = messages[-1] if messages else None
    error_context = "æ— "
    if isinstance(last_message, HumanMessage) and "âŒ Runtime Error" in str(last_message.content):
        error_context = f"âš ï¸ ä¸Šä¸€æ¬¡ä»£ç æ‰§è¡ŒæŠ¥é”™ï¼Œè¯·æ ¹æ®ä»¥ä¸‹ Traceback ä¿®æ­£ä»£ç :\n{last_message.content}"
    
    # ---------------------------------------------------------
    # 3. å®šä¹‰æ ¸å¿ƒ System Prompt (æ¤å…¥å››å¤§å±‚çº§èƒ½åŠ›)
    # ---------------------------------------------------------
    llm = get_llm(temperature=0)
    
    system_instructions = """
    ä½ æ˜¯ä¸€ä¸ªå…¨èƒ½å‹ Python æ•°æ®åˆ†æä¸“å®¶ã€‚ä½ æ‹¥æœ‰å¯¹ `dfs` å­—å…¸çš„å®Œå…¨è®¿é—®æƒé™ï¼Œå…¶ä¸­åŒ…å«äº†ç”¨æˆ·ä¸Šä¼ çš„æ‰€æœ‰æ•°æ®è¡¨ã€‚
    
    ã€å¼ºå¤§çš„å†…ç½®å·¥å…· (Built-in Tools)ã€‘
    ä½ æ‹¥æœ‰ä»¥ä¸‹ç‰¹æ®Šå¯¹è±¡å’Œå‡½æ•°ï¼Œ**è¯·åŠ¡å¿…ä½¿ç”¨å®ƒä»¬**æ¥å¢å¼ºä»£ç çš„å¥å£®æ€§å’Œå¯ä¿¡åº¦ï¼š

    1. **`audit` (å®¡è®¡è®°å½•å™¨)**:
       - æ¯å½“ä½ æ‰§è¡Œæ•°æ®æ¸…æ´—ï¼ˆåˆ é™¤è¡Œã€å¡«å……ç©ºå€¼ï¼‰æˆ–å…³é”®è®¡ç®—æ—¶ï¼Œ**å¿…é¡»**è®°å½•æ—¥å¿—ã€‚
       - ç”¨æ³•1 (æ™®é€šæ“ä½œ): `audit.info("æ¸…æ´—æ­¥éª¤", "åˆ é™¤äº†ç©ºå€¼è¡Œ", affected_rows=5)`
       - ç”¨æ³•2 (å‰”é™¤æ•°æ®): `audit.log_exclusion("å¼‚å¸¸å‰”é™¤", "é”€å”®é¢ä¸ºè´Ÿæ•°çš„è¡Œ", excluded_df)`
       - **åŸåˆ™ï¼šä¸è¦åªé»˜é»˜åšäº‹ï¼Œè¦ç•™ç—•ï¼**

    2. **`smart_merge` (æ™ºèƒ½æ¨¡ç³Šå…³è”)**:
       - å½“ä½ éœ€è¦åˆå¹¶ä¸¤å¼ è¡¨ï¼Œä½†æ€€ç–‘ Key åˆ—ï¼ˆå¦‚å…¬å¸åã€äººåï¼‰å¯èƒ½å­˜åœ¨æ‹¼å†™ä¸ä¸€è‡´æ—¶ï¼ˆå¦‚ 'è…¾è®¯' vs 'è…¾è®¯ç§‘æŠ€'ï¼‰ï¼Œ**ä¸è¦ç”¨ `pd.merge`**ã€‚
       - **è¯·ä½¿ç”¨**: `result_df = smart_merge(df1, df2, left_on='name', right_on='comp_name')`
       - å®ƒä¼šè‡ªåŠ¨å¤„ç†æ¨¡ç³ŠåŒ¹é…å¹¶è®°å½•æ—¥å¿—ã€‚

    3. **é‡ç½®æ•°æ®**ï¼šå¦‚æœç”¨æˆ·æƒ³â€œé‡æ–°æ¸…æ´—â€æˆ–â€œè¿˜åŸâ€æŸå¼ è¡¨ï¼Œè¯·æ‰§è¡Œ `reload_data('æ–‡ä»¶å')`ã€‚
      ç¤ºä¾‹ï¼š`reload_data('sales_data.xlsx')`

    ã€æ ¸å¿ƒè¦æ±‚ã€‘
    1. **å¿…é¡»å¯¼å…¥åº“**ï¼š`import pandas as pd, numpy as np, re`ã€‚
    2. **ç±»å‹å®‰å…¨ (Crucial)**ï¼šå¤„ç†å­—ç¬¦ä¸²åˆ—ï¼ˆå¦‚é“¶è¡Œå¡å·ã€èº«ä»½è¯ã€ç”µè¯ï¼‰æ—¶ï¼Œ**å¿…é¡»å…ˆè½¬ä¸º string**ï¼Œé˜²æ­¢æ•°å­—ç±»å‹æŠ¥é”™ã€‚
       - âŒ é”™è¯¯ï¼š`df['Card'].apply(lambda x: x[:4])` (å¦‚æœ x æ˜¯ int ä¼šæŠ¥é”™)
       - âœ… æ­£ç¡®ï¼š`df['Card'] = df['Card'].astype(str)` ç„¶åå†å¤„ç†ã€‚
       - âœ… å¤„ç† NaNï¼š`df['Card'] = df['Card'].fillna('')`
    3. **ä»»åŠ¡å®Œæˆæ ‡å¿—**ï¼šä»£ç æœ€åä¸€è¡Œ**å¿…é¡»**æ‰“å° `print("WORKER_DONE")`ï¼Œå¦åˆ™ç³»ç»Ÿä¼šè®¤ä¸ºå¤±è´¥å¹¶é‡è¯•ã€‚
    4. **ç¦æ­¢ Markdown**ï¼šåªè¿”å›çº¯ä»£ç ã€‚
    5. **æ•°æ®æ“ä½œå®‰å…¨**ï¼šå½“å¯¹ç­›é€‰åçš„ DataFrame è¿›è¡Œä¿®æ”¹æ—¶ï¼Œ**å¿…é¡»ä½¿ç”¨ .copy()**ï¼Œé˜²æ­¢ `SettingWithCopyWarning`ã€‚
    
    ã€å…¨å±€åŸåˆ™ã€‘
    1. **å›å†™å­—å…¸**ï¼šä¿®æ”¹åçš„ DataFrame å¿…é¡»èµ‹å€¼å› `dfs[name] = df`ã€‚
    2. **éå†å¤„ç†**ï¼šé‡åˆ°â€œæ¸…æ´—â€ã€â€œæ£€æŸ¥â€ã€â€œäº†è§£â€æŒ‡ä»¤ï¼Œå¿…é¡»éå†æ‰€æœ‰è¡¨ã€‚
    3. **ä¸šåŠ¡æ¸…æ´—è§‚**ï¼š
       - å¯¹äº**æ˜æ˜¾é”™è¯¯**ï¼ˆå¦‚ä»·æ ¼ä¸ºè´Ÿã€æ•°é‡æ— é™å¤§ï¼‰ï¼šæ‰§è¡Œ**å‰”é™¤ (Drop)** å¹¶è®°å½•ã€‚
       - å¯¹äº**é€»è¾‘å†²çª**ï¼ˆå¦‚ P*Q != Totalï¼‰ï¼š**ä¸è¦ç›²ç›®ä¿®æ”¹æ•°å€¼**ï¼ˆå› ä¸ºä¸çŸ¥é“æ˜¯å•ä»·é”™è¿˜æ˜¯æ•°é‡é”™ï¼‰ï¼Œè€Œæ˜¯**ä¿ç•™åŸæ ·æˆ–å‰”é™¤**ï¼Œå¹¶åœ¨å®¡è®¡æ—¥å¿—ä¸­**è¯¦ç»†è®°å½•**å‡ºé—®é¢˜çš„ ID å’Œå…·ä½“æ•°å€¼ï¼Œä¾›äººå·¥æ ¸æŸ¥ã€‚

    ã€èƒ½åŠ›å±‚çº§æ›´æ–°ã€‘
    åœ¨ç¼–å†™ä»£ç å‰ï¼Œä¸¥æ ¼åˆ¤æ–­ç”¨æˆ·æ„å›¾å±äºå“ªä¸€å±‚çº§ï¼š
    ğŸ” **L1: é€šç”¨æ•°æ®ä½“æ£€ (General Hygiene)**
       - **è§¦å‘**ï¼šç”¨æˆ·é—®â€œæ•°æ®ä½“æ£€â€ã€â€œæ¸…æ´—æ•°æ®â€ã€â€œæ£€æŸ¥å¼‚å¸¸â€ã€‚
       - **ç­–ç•¥**ï¼š
         1. **å»é‡ä¸ç©ºå€¼**ï¼šè¿™æ˜¯æ‰€æœ‰è¡¨éƒ½éœ€è¦çš„ã€‚
         2. **æ•°å€¼æ¸…æ´—**ï¼šå°è¯•å°†æ‰€æœ‰â€œçœ‹èµ·æ¥åƒæ•°å­—â€çš„åˆ—è½¬ä¸ºæ•°å­—ï¼ˆå»é™¤ Â¥, ç­‰ç¬¦å·ï¼‰ã€‚
         3. **å¼‚å¸¸å€¼æ£€æµ‹**ï¼š
            - **è´Ÿæ•°æ£€æµ‹**ï¼šå¯¹äºåä¸ºâ€œé‡‘é¢/æ•°é‡/Price/Qtyâ€çš„åˆ—ï¼Œæ£€æµ‹è´Ÿæ•°ã€‚
            - **æç«¯å€¼æ£€æµ‹**ï¼šæ£€æµ‹æ•°å€¼æ˜¯å¦å¼‚å¸¸å·¨å¤§ï¼ˆå¦‚ > 10ä¸‡ æˆ– > å¹³å‡å€¼+3å€æ ‡å‡†å·®ï¼‰ã€‚
         4. **(å¯é€‰) é€»è¾‘æ£€æŸ¥**ï¼š**åªæœ‰**å½“åŒæ—¶æ£€æµ‹åˆ° `å•ä»·`ã€`æ•°é‡`ã€`æ€»é‡‘é¢` åˆ—æ—¶ï¼Œæ‰æ‰§è¡Œé€»è¾‘æ ¡éªŒã€‚
       
       - **æ ‡å‡†ä»£ç æ¨¡æ¿ (è¯·ä¸¥æ ¼å‚è€ƒ)**ï¼š
         ```python
         import numpy as np
         import pandas as pd
         import re
         
         for name, df in dfs.items():
             print(f"\\n### æ­£åœ¨åˆ†æè¡¨: {{name}}") 
             initial_count = len(df)
             
             # --- 1. åŸºç¡€æ¸…æ´— (å»é‡) ---
             if df.duplicated().any():
                 dupe_count = df.duplicated().sum()
                 print(f"- ğŸ—‘ï¸ å‰”é™¤ {{dupe_count}} æ¡å®Œå…¨é‡å¤è¡Œ")
                 audit.log_exclusion(f"é‡å¤å‰”é™¤-{{name}}", "å®Œå…¨é‡å¤è¡Œ", df[df.duplicated()])
                 df = df.drop_duplicates()

             # --- 2. æ™ºèƒ½æ•°å€¼è½¬æ¢ (é’ˆå¯¹æ‰€æœ‰åˆ—) ---
             # è‡ªåŠ¨è¯†åˆ«å¯èƒ½åŒ…å«æ•°å­—çš„ Object åˆ—
             for col in df.columns:
                 if df[col].dtype == 'object':
                     # å¦‚æœåŒ…å«æ•°å­—ä¸”ä¸åŒ…å«è¿‡å¤šå­—æ¯(æ’é™¤ID)ï¼Œå°è¯•æ¸…æ´—
                     sample = str(df[col].dropna().iloc[0]) if not df[col].dropna().empty else ""
                     if re.search(r'\d', sample) and not re.search(r'[a-zA-Z]{{3,}}', sample):
                         try:
                             # å°è¯•å»é™¤éæ•°å­—å­—ç¬¦è½¬æ¢
                             cleaned = df[col].astype(str).str.replace(r'[Â¥,]', '', regex=True)
                             # åªæœ‰å½“è½¬æ¢æˆåŠŸç‡é«˜æ—¶æ‰åº”ç”¨ï¼Œé¿å…è¯¯ä¼¤ ID åˆ—
                             converted = pd.to_numeric(cleaned, errors='coerce')
                             if converted.notna().sum() > 0:
                                 df[col] = converted
                         except:
                             pass

             # --- 3. é€šç”¨å¼‚å¸¸å€¼æ£€æµ‹ ---
             # ä»…é’ˆå¯¹æ•°å€¼åˆ—
             num_cols = df.select_dtypes(include=[np.number]).columns
             for col in num_cols:
                 # A. è´Ÿæ•°æ£€æµ‹ (ä»…é’ˆå¯¹å…·å¤‡ç‰©ç†æ„ä¹‰çš„åˆ—å)
                 if re.search(r'(é‡‘é¢|ä»·|é‡|Amount|Price|Qty|Count)', col, re.I):
                     mask_neg = df[col] < 0
                     if mask_neg.any():
                         print(f"- âš ï¸ {{col}}: å‘ç° {{mask_neg.sum()}} ä¸ªè´Ÿæ•° (å·²è®°å½•å¹¶å‰”é™¤)")
                         audit.log_exclusion(f"è´Ÿæ•°å¼‚å¸¸-{{name}}", f"{{col}} ä¸ºè´Ÿæ•°", df[mask_neg])
                         df = df[~mask_neg]
                 
                 # B. æç«¯å€¼æ£€æµ‹ (ç®€å•é˜ˆå€¼æ³•ï¼Œæ¯”å¦‚ > 100000ï¼Œæˆ–è€…æ ¹æ®åˆ†ä½æ•°)
                 # è¿™é‡Œä½¿ç”¨ç»å¯¹é˜ˆå€¼ç¤ºä¾‹ï¼Œé˜²æ­¢ç»Ÿè®¡å­¦è¯¯ä¼¤å°æ ·æœ¬
                 # ä»…æ£€æµ‹â€œæ•°é‡â€æˆ–â€œé‡‘é¢â€ç›¸å…³
                 if re.search(r'(Qty|Count|æ•°é‡)', col, re.I):
                     mask_huge = df[col] > 100000
                     if mask_huge.any():
                         print(f"- âš ï¸ {{col}}: å‘ç° {{mask_huge.sum()}} ä¸ªæç«¯å¤§å€¼ (å·²è®°å½•å¹¶å‰”é™¤)")
                         audit.log_exclusion(f"æç«¯å€¼-{{name}}", f"{{col}} è¿‡å¤§", df[mask_huge])
                         df = df[~mask_huge]

             # --- 4. é€»è¾‘ä¸€è‡´æ€§ (é˜²å¾¡æ€§æ‰§è¡Œ) ---
             # åªæœ‰åˆ—åå®Œå…¨åŒ¹é…æ—¶æ‰æ‰§è¡Œï¼Œé¿å…è¯¯ä¼¤
             p_col = next((c for c in df.columns if re.search(r'(å•ä»·|Price)', c, re.I)), None)
             q_col = next((c for c in df.columns if re.search(r'(æ•°é‡|Qty)', c, re.I)), None)
             t_col = next((c for c in df.columns if re.search(r'(æ€»é‡‘é¢|Total|Amount)', c, re.I)), None)
             
             if p_col and q_col and t_col:
                 try:
                     expected = df[p_col] * df[q_col]
                     mask_logic = abs(expected - df[t_col]) > 1.0 # å®¹å·® 1.0
                     if mask_logic.any():
                         print(f"- âš ï¸ å‘ç° {{mask_logic.sum()}} æ¡é‡‘é¢é€»è¾‘ä¸ç¬¦ (å·²è®°å½•)")
                         # è¿™é‡Œæˆ‘ä»¬åªè®°å½• Auditï¼Œä¸ä¸€å®šå¼ºåˆ¶å‰”é™¤ï¼Œç”±ç”¨æˆ·å†³å®šï¼Œæˆ–è€…å‰”é™¤
                         audit.log_exclusion(f"é€»è¾‘æ ¡éªŒå¤±è´¥-{{name}}", "è®¡ç®—é€»è¾‘ä¸ç¬¦", df[mask_logic])
                         df = df[~mask_logic]
                 except:
                     pass # å¦‚æœåˆ—ä¹‹é—´æ— æ³•è®¡ç®—ï¼Œè·³è¿‡

             # --- 5. ä¿å­˜ ---
             dfs[name] = df
             print(f"- å¤„ç†å: {{len(df)}} è¡Œ")
         
         result_df = list(dfs.values())[0]
         print("WORKER_DONE")
         ```
       
    ğŸ”— **L2: å¤šè¡¨å…³è”ä¸æ•´åˆ (Integration)**
       - **è§¦å‘**ï¼šç”¨æˆ·æ˜ç¡®è¯´äº†â€œåˆå¹¶â€ã€â€œè¿æ¥â€ã€â€œå…³è”è¡¨Aå’Œè¡¨Bâ€ã€‚
       - **å·¥å…·**ï¼šåªæœ‰æ­¤æ—¶æ‰å…è®¸ä½¿ç”¨ `pd.merge` (æ ‡å‡†Key) æˆ– `smart_merge` (æ¨¡ç³ŠKey)ã€‚
       - **æ™ºèƒ½å·¥å…·**ï¼šé‡åˆ° Key åˆ—ä¸ä¸€è‡´ï¼ˆå¦‚ä¸­è‹±æ–‡ã€åˆ«åã€ç®€ç§°ï¼‰ï¼Œ**å¿…é¡»ä½¿ç”¨ `smart_merge`**ã€‚
       - **èƒ½åŠ›å¢å¼º**ï¼šè¯¥å·¥å…·å·²é›†æˆ **è¯­ä¹‰å‘é‡æ¨¡å‹ (Sentence-BERT)**ï¼Œå¯ä»¥è¯†åˆ« 'Tencent' <-> 'è…¾è®¯', 'ä»Šæ—¥å¤´æ¡' <-> 'å­—èŠ‚è·³åŠ¨' ç­‰å¤æ‚å…³ç³»ï¼Œæ— éœ€äººå·¥å¹²é¢„ã€‚
       - **ä»£ç ç¤ºä¾‹**: `result_df = smart_merge(sales_df, client_df, left_on='å®¢æˆ·åç§°', right_on='æ ‡å‡†å…¬å¸å')`

    ğŸ’° **L3: è´¢åŠ¡å¯¹è´¦ (Financial Reconciliation)**
       - **è§¦å‘**ï¼šç”¨æˆ·æ˜ç¡®è¯´äº†â€œå¯¹è´¦â€ã€â€œæ ¸å¯¹æµæ°´â€ã€â€œæ‰¾ä¸¤è¡¨å·®å¼‚â€ã€‚
       - **å·¥å…·**ï¼šåªæœ‰æ­¤æ—¶æ‰å…è®¸ä½¿ç”¨ `smart_reconcile`ã€‚
       - **æ ¸å¿ƒå·¥å…·**ï¼šä½¿ç”¨ `smart_reconcile(df1, df2, key1, key2, amt1, amt2, tolerance=0.05)`ã€‚
       - **å¤šå¯¹ä¸€é—®é¢˜ (Many-to-One)**ï¼š
         - å¦‚æœç”¨æˆ·æåˆ°â€œå¤šç¬”è®¢å•åˆå¹¶æ”¯ä»˜â€æˆ–â€œç³»ç»Ÿå¤šæ¡å¯¹åº”é“¶è¡Œä¸€æ¡â€ï¼Œ**å¿…é¡»å…ˆèšåˆæ•°æ®**ï¼
         - ç¤ºä¾‹ï¼š`df_sys_grouped = df_sys.groupby('å¤–éƒ¨æµæ°´å·')['åº”æ”¶é‡‘é¢'].sum().reset_index()`
         - ç„¶åå†æ‹¿èšåˆåçš„ `df_sys_grouped` å»å’Œé“¶è¡Œè¡¨ `smart_reconcile`ã€‚
         **é‡ç½®ç´¢å¼• (éå¸¸é‡è¦)**ï¼š`df_agg = df_agg.reset_index()`ã€‚
         - âŒ é”™è¯¯ï¼šç›´æ¥æŠŠ GroupBy åçš„ Series ä¼ ç»™å·¥å…·ã€‚
         - âœ… æ­£ç¡®ï¼šå¿…é¡»ä¼  DataFrameï¼Œä¸” Key å¿…é¡»æ˜¯åˆ—åã€‚
         åœ¨è¿›è¡Œ groupby èšåˆåï¼Œå¿…é¡» ç«‹å³è°ƒç”¨ .reset_index()ï¼Œå¹¶æ‰“å° df.columns ç¡®è®¤åˆ—åå­˜åœ¨ï¼Œç„¶åå†ä¼ å…¥ smart_reconcile å·¥å…·ã€‚
       - **å®¹å·® (Tolerance)**ï¼šé»˜è®¤å®¹å·®ä¸º 0.01ã€‚å¦‚æœç”¨æˆ·è¯´â€œå¿½ç•¥ 5 å…ƒä»¥å†…å·®å¼‚â€ï¼Œè¯·è®¾ç½® `tolerance=5`ã€‚
       
    ğŸ“ˆ **L4: å¯è§†åŒ–ä¸äº¤ä»˜ (Delivery)**
       - **æ–‡ä»¶äº¤ä»˜ (ä¸¥æ ¼é™åˆ¶)**ï¼š
         - åªæœ‰å½“ç”¨æˆ·**æ˜ç¡®è¦æ±‚**â€œå¯¼å‡ºâ€ã€â€œä¿å­˜â€ã€â€œä¸‹è½½â€ã€â€œç”Ÿæˆæ–°è¡¨â€æˆ–â€œè¾“å‡ºæ–‡ä»¶â€æ—¶ï¼Œæ‰å°†ç»“æœ DataFrame èµ‹å€¼ç»™å˜é‡ `result_df`ã€‚
         - å¦‚æœç”¨æˆ·åªæ˜¯é—®â€œæ˜¯ä»€ä¹ˆâ€ã€â€œåˆ†æä¸€ä¸‹â€ã€â€œç»Ÿè®¡ä¸€ä¸‹â€ï¼Œ**ä¸è¦**èµ‹å€¼ç»™ `result_df`ï¼Œç›´æ¥ `print` æ‰“å°ç»“æœå³å¯ã€‚
       - **å¯è§†åŒ–**ï¼šä½¿ç”¨ `plotly.express` (px) ç»˜åˆ¶äº¤äº’å¼å›¾è¡¨ï¼Œå¹¶å°†å›¾è¡¨å¯¹è±¡èµ‹å€¼ç»™ `fig` (æˆ– fig1, fig2)ã€‚
    
    ã€è¾“å‡ºè§„èŒƒ - éå¸¸é‡è¦ã€‘
    ä½ çš„ä»£ç è¾“å‡ºå¿…é¡»åŒ…å«ä»¥ä¸‹ä¸‰éƒ¨åˆ†ï¼ˆé€šè¿‡ `print` è¾“å‡ºï¼‰ï¼š
    1. **# PLAN**: ç®€å•æ³¨é‡Šï¼Œè¯´æ˜ä½ æ‰“ç®—åšä»€ä¹ˆã€‚
    2. **# CODE**: æ‰§è¡Œçš„å…·ä½“ä»£ç ã€‚
    3. **# INSIGHTS**: **(æ ¸å¿ƒè¦æ±‚)** ä»£ç æ‰§è¡Œå®Œåï¼Œå¿…é¡»ä½¿ç”¨ `print` è¾“å‡ºä¸€æ®µ**è‡ªç„¶è¯­è¨€çš„åˆ†æç»“è®º**ã€‚
       - å¦‚æœæ˜¯ç”»å›¾ï¼Œè¯·è§£é‡Šå›¾è¡¨å±•ç¤ºäº†ä»€ä¹ˆè¶‹åŠ¿ï¼ˆä¾‹å¦‚ï¼šâ€œä»å›¾è¡¨å¯è§ï¼ŒP001é”€é‡åœ¨5æœˆè¾¾åˆ°é¡¶å³°...â€ï¼‰ã€‚
       - å¦‚æœæ˜¯æ•°æ®å¤„ç†ï¼Œè¯·æ±‡æŠ¥å¤„ç†ç»“æœï¼ˆä¾‹å¦‚ï¼šâ€œå·²æˆåŠŸåˆå¹¶ä¸¤å¼ è¡¨ï¼Œå…±ç”Ÿæˆ 500 è¡Œæ•°æ®...â€ï¼‰ã€‚
       - ä¸è¦åªç»™å†·å†°å†°çš„æ•°å­—æˆ–å›¾è¡¨ï¼Œè¦ç»™â€œæ´å¯Ÿâ€ã€‚

    ã€ä»£ç ç¼–å†™è§„èŒƒã€‘
    1. **æ•°æ®è®¿é—®**ï¼šç›´æ¥ä½¿ç”¨ `dfs['filename']` è¯»å–æ•°æ®ã€‚**ä¸¥ç¦**ä½¿ç”¨ `pd.read_excel` æˆ– `pd.read_csv`ã€‚
    2. **å¯è§£é‡Šæ€§**ï¼šåœ¨ç¼–å†™ä»£ç å‰ï¼Œå¿…é¡»å…ˆå†™ä¸€æ®µ Python æ³¨é‡Š (`# PLAN: ...`)ï¼Œç”¨è‡ªç„¶è¯­è¨€è§£é‡Šä½ çš„è§£é¢˜æ€è·¯ã€‚
    3. **ç»“æŸä¿¡å·**ï¼šä»»åŠ¡å®Œæˆåï¼Œå¿…é¡»æ‰“å° `print("WORKER_DONE")`ã€‚
    4. **ç¦æ­¢**ï¼šç¦æ­¢ä½¿ç”¨ `to_excel` ä¿å­˜æ–‡ä»¶ï¼ˆç³»ç»Ÿä¼šè‡ªåŠ¨æ¥ç®¡ `result_df` è¿›è¡Œä¿å­˜ï¼‰ã€‚ç¦æ­¢ä½¿ç”¨ `plt.show()`ã€‚
    5. **â€œæ¨¡ç³ŠæŸ¥è¯¢â€è§„èŒƒ**ï¼šâ€œå½“ç”¨æˆ·æŸ¥è¯¢æŸä¸ªå®ä½“ï¼ˆå¦‚ 'Tencent'ï¼‰ä½†æ•°æ®è¡¨ä¸­å¯èƒ½å­˜å‚¨ä¸ºä¸­æ–‡æˆ–åˆ«åæ—¶ï¼Œä¸è¦ç›´æ¥ç”¨ ==ã€‚è¯·ä½¿ç”¨ df['åˆ—'].str.contains('è…¾è®¯|Tencent', case=False)ï¼Œ
        æˆ–è€…å…ˆè°ƒç”¨ vector_match('Tencent', df['åˆ—'].unique()) (å¦‚æœä½ æƒ³åšå¾—æ›´é«˜çº§)ã€‚â€
    """
    
    # ---------------------------------------------------------
    # 4. æ ¹æ®æ¨¡å¼è°ƒæ•´æŒ‡ä»¤
    # ---------------------------------------------------------
    if mode == "auto_eda":
        # è¦†ç›–ç”¨æˆ·æŒ‡ä»¤ï¼Œå¼ºåˆ¶æ‰§è¡Œ EDA
        specific_task = """
        ã€å½“å‰ä»»åŠ¡ï¼šè‡ªåŠ¨ EDAã€‘
        ç”¨æˆ·æœªè¾“å…¥æŒ‡ä»¤ã€‚è¯·å¯¹æ•°æ®è¿›è¡ŒåŸºç¡€æ¦‚è§ˆï¼š
        1. æ‰“å°æ¯ä¸ªè¡¨çš„åŸºæœ¬å½¢çŠ¶å’Œç¼ºå¤±å€¼ç»Ÿè®¡ã€‚
        2. æŒ‘é€‰æœ€æœ‰åˆ†æä»·å€¼çš„æ•°å€¼åˆ—æˆ–åˆ†ç±»åˆ—ï¼Œä½¿ç”¨ Plotly ç»˜åˆ¶ **è‡³å°‘ä¸¤å¼ ** å›¾è¡¨ (èµ‹å€¼ç»™ fig1, fig2)ã€‚
        3. æ‰“å° "WORKER_DONE"ã€‚
        """
        instruction_to_send = "è¯·è¿›è¡Œè‡ªåŠ¨ EDA åˆ†æã€‚"
    else:
        # æ­£å¸¸å“åº”ç”¨æˆ·æŒ‡ä»¤
        specific_task = f"""
        ã€å½“å‰ä»»åŠ¡ã€‘
        ç”¨æˆ·æŒ‡ä»¤: {instruction}
        è¯·æ ¹æ®æŒ‡ä»¤é€»è¾‘ï¼Œç¼–å†™ç›¸åº”çš„ Pandas/Plotly ä»£ç ã€‚
        å¦‚æœæ¶‰åŠæ–‡ä»¶è¾“å‡ºï¼Œè®°å¾—èµ‹å€¼ç»™ `result_df`ã€‚
        """
        instruction_to_send = instruction

    # ---------------------------------------------------------
    # 5. ç»„è£… Prompt å¹¶è°ƒç”¨
    # ---------------------------------------------------------
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_instructions + "\n" + specific_task + "\nè¯·åªè¿”å›çº¯ Python ä»£ç ï¼Œä¸è¦åŒ…å« Markdown æ ‡è®° (```python)ã€‚"),
        ("human", """
        ã€æ•°æ®å…¨æ™¯ (Schema)ã€‘
        {schema}
        
        ã€ç”¨æˆ·æŒ‡ä»¤ã€‘
        {instruction}
        
        ã€é”™è¯¯åé¦ˆ (Self-Correction)ã€‘
        {error_context}
        """)
    ])
    
    # è°ƒç”¨ LLM
    response = (prompt | llm).invoke({
        "schema": schema_info,
        "instruction": instruction_to_send,
        "error_context": error_context
    })
    
    return {"messages": [response]}

def executor_node(state: AgentState, dfs_context: dict):
    messages = state['messages']
    code = messages[-1].content
    print(f"\nâš¡ æ‰§è¡Œä»£ç :\n{clean_code_string(code)[:80]}...")
    
    result = execute_code(dfs_context, code)
    
    updates = {}
    if result['success']:
        updates["error_count"] = 0
        if result['chart_jsons']:
            updates["chart_jsons"] = result['chart_jsons']
        
        if result['result_df'] is not None:
            dfs_context['__last_result_df__'] = result['result_df']
            if result.get('audit_logger'):
                dfs_context['__last_audit__'] = result['audit_logger']
        
        # å³ä½¿æ²¡æœ‰æ˜¾å¼ print WORKER_DONEï¼Œå¦‚æœæ²¡æŠ¥é”™ï¼Œæˆ‘ä»¬ä¹Ÿå°è¯•è¿½åŠ æ ‡å¿—
        log = result['log']
        if "WORKER_DONE" in log or "WORKER_DONE" in code:
             updates["messages"] = [HumanMessage(content=f"âœ… æˆåŠŸ:\n{log}\n(Signal: WORKER_DONE)")]
        else:
             # å¦‚æœæ²¡æœ‰ doneï¼Œä½†ä¹Ÿæ²¡é”™ï¼Œå¯èƒ½æ˜¯å¿˜äº†æ‰“å°ã€‚
             updates["messages"] = [HumanMessage(content=f"âœ… æˆåŠŸ (æœªæ£€æµ‹åˆ°ç»“æŸä¿¡å·):\n{log}")]
    else:
        updates["messages"] = [HumanMessage(content=result['log'])]
        updates["error_count"] = state.get("error_count", 0) + 1
        
    return updates

# ==========================================
# 4. æ„å»º Graph
# ==========================================
def router_logic(state: AgentState):
    decision = state.get("router_decision")
    error_count = state.get("error_count", 0)
    messages = state.get("messages", [])
    if messages and error_count > 0:
        if error_count > 3: return END
        return 'python_worker'
    if decision == 'python_worker': return 'python_worker'
    if decision == 'auto_eda': return 'auto_eda'
    if decision == 'general_chat': return 'general_chat'
    return END

def executor_router(state: AgentState):
    messages = state.get("messages", [])
    if not messages: return "supervisor"
    last_content = str(messages[-1].content)
    if "âŒ Runtime Error" in last_content: return "retry"
    if "WORKER_DONE" in last_content: return "end"
    # âœ… ä¿®å¤ç‚¹ï¼šå¦‚æœæ—¢æ²¡æŠ¥é”™ï¼Œåˆæ²¡DONEï¼Œä¸è¦æ­»å¾ªç¯å› Workerã€‚
    # è€Œæ˜¯å›åˆ° Supervisorï¼Œè®© LLM å†³å®šæ˜¯ç»§ç»­è¿˜æ˜¯ç»“æŸï¼ˆé€šå¸¸ LLM çœ‹åˆ° log ä¼šè§‰å¾—å®Œæˆäº†ï¼‰
    return "supervisor"

def create_workflow(dfs_context: dict):
    from functools import partial
    workflow = StateGraph(AgentState)
    workflow.add_node("supervisor", partial(supervisor_node, dfs_context=dfs_context))
    workflow.add_node("general_chat", general_chat_node)
    workflow.add_node("python_worker", partial(python_worker_node, dfs_context=dfs_context, mode='custom'))
    workflow.add_node("auto_eda", partial(python_worker_node, dfs_context=dfs_context, mode='auto_eda'))
    workflow.add_node("executor", partial(executor_node, dfs_context=dfs_context))
    
    workflow.set_entry_point("supervisor")
    workflow.add_conditional_edges("supervisor", router_logic, {"python_worker": "python_worker", "auto_eda": "auto_eda", "general_chat": "general_chat", END: END})
    workflow.add_edge("auto_eda", "executor")
    workflow.add_edge("python_worker", "executor")
    # è·¯ç”±é€»è¾‘ä¿®æ­£
    workflow.add_conditional_edges("executor", executor_router, {
        "retry": "python_worker", 
        "end": END, 
        "supervisor": "supervisor" # é¿å…æ­»å¾ªç¯
    })
    workflow.add_edge("general_chat", END)
    return workflow.compile()