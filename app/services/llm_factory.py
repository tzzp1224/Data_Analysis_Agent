# LLMå·¥å‚æ¨¡å¼ã€‚è´Ÿè´£ç”Ÿäº§ LLM å®ä¾‹ï¼Œç»Ÿä¸€ç®¡ç†å‚æ•°ï¼ˆå¦‚ Temperatureï¼‰å’Œå®‰å…¨è®¾ç½®ã€‚
from langchain_google_genai import ChatGoogleGenerativeAI, HarmBlockThreshold, HarmCategory
from app.core.config import settings

def get_llm(temperature=0):
    """
    è·å– Google Gemini LLM å®ä¾‹ã€‚
    """
    if not settings.GOOGLE_API_KEY:
        raise ValueError("âŒ æœªæ‰¾åˆ° GOOGLE_API_KEYï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶")

    return ChatGoogleGenerativeAI(
        google_api_key=settings.GOOGLE_API_KEY,
        model=settings.GOOGLE_MODEL_NAME,
        temperature=temperature,
        # ğŸ‘‡ å…³æ‰å®‰å…¨è¿‡æ»¤ï¼Œé˜²æ­¢åˆ†ææ•°æ®æ—¶è¯¯æŠ¥
        safety_settings={
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
        }
    )